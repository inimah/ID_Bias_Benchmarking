# ID_Bias_Benchmarking
This repository is dedicated to the collection of research papers on Bias Datasets and Benchmarking, to be adopted to Indonesian use cases.


## Content
- [Papers](#papers)
- [How to Contribute](#how-to-contribute)

## Papers
Here, you'll find a curated list of academic papers, articles, and publications that explore the intersections of AI, Language Models, and cultural value alignment.

### Taxonomy: Gender bias, Cultural dimension
- (12-2024) [GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models](https://arxiv.org/abs/2406.13925)
- (11-2023) [CDEval: A Benchmark for Measuring the Cultural Dimensions of Large Language Models](https://arxiv.org/abs/2311.16421)
- (7-2021) [Gender Bias in Text: Origin, Taxonomy, and Implications](https://aclanthology.org/2021.gebnlp-1.5/)

### General: LLM Bias
- (4-2023) [Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models](https://arxiv.org/pdf/2304.03738.pdf)
- (3-2023) [Whose Opinions Do Language Models Reflect?](https://arxiv.org/pdf/2303.17548.pdf)
- (2021) [Gender bias, social bias, and representation in Bollywood and Hollywood](https://www.sciencedirect.com/science/article/pii/S266638992100283X)
- (2020) [UNQOVERing Stereotypical Biases via Underspecified Questions](https://arxiv.org/abs/2010.02428)

### National Bias
- (8-2023) [Unmasking Nationality Bias: A Study of Human Perception of Nationalities in AI-Generated Articles](https://arxiv.org/abs/2308.04346)
- (2-2023) [Nationality Bias in Text Generation](https://arxiv.org/abs/2302.02463)
- (2022) [French CrowS-Pairs: Extending a challenge dataset for measuring social bias in masked language models to a language other than English](https://aclanthology.org/2022.acl-long.583/)

### SEA Benchmark datasets
- (11-2024) [SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages](https://aclanthology.org/2024.emnlp-main.296/)
- (10-2024) [WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines](https://arxiv.org/abs/2410.12705)
- (9-2024) [Kalahi: A handcrafted, grassroots cultural LLM evaluation suite for Filipino](https://arxiv.org/abs/2409.15380)
- (8-2024) [Cendol: Open Instruction-tuned Generative Large Language Models for Indonesian Languages](https://aclanthology.org/2024.acl-long.796/)
- (4-2024) [IndoCulture: Exploring Geographically-Influenced Cultural Commonsense Reasoning Across Eleven Indonesian Provinces](https://arxiv.org/abs/2404.01854)
- (11-2023) [Instruction-Following Evaluation for Large Language Models](https://arxiv.org/abs/2311.07911)
- (9-2023) [BHASA: A Holistic Southeast Asian Linguistic and Cultural Evaluation Suite for Large Language Models](https://arxiv.org/abs/2309.06085)
  
### Cultural Bias
- (5-2023) [Having Beer after Prayer? Measuring Cultural Bias in Large Language Models](https://arxiv.org/abs/2305.14456)
- (3-2023) [Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study](https://arxiv.org/abs/2303.17466)
- (3-2023) [Probing Pre-Trained Language Models for Cross-Cultural Differences in Values](https://arxiv.org/abs/2203.13722)

### Cultural alignment
- (2-2024) [Investigating Cultural Alignment of Large Language Models](https://arxiv.org/abs/2402.13231)
- (2-2024) [CIDAR: Culturally Relevant Instruction Dataset For Arabic](https://arxiv.org/abs/2402.03177)
- (8-2023) [Cultural Alignment in Large Language Models: An Explanatory Analysis Based on Hofstede's Cultural Dimensions](https://arxiv.org/abs/2309.12342)
- (2022) [Cultural Incongruencies in Artificial Intelligence](https://arxiv.org/pdf/2211.13069.pdf)
- (2022) [The Myth of Culturally Agnostic AI Models](https://arxiv.org/ftp/arxiv/papers/2211/2211.15271.pdf)

### Alignment and Preference tuning
- (10-2024) [A Grounded Preference Model for LLM Alignment](https://aclanthology.org/2024.findings-acl.10/)
- (6-2024) [Safer-Instruct: Aligning Language Models with Automated Preference Data](https://aclanthology.org/2024.naacl-long.422/)
- (4-2024) [Soft Preference Optimization: Aligning Language Models to Expert Distributions](https://arxiv.org/abs/2405.00747)
- (9-2023) [Large Language Model Alignment: A Survey](https://arxiv.org/abs/2309.15025)
- (8-2023) [Group Preference Optimization: Few-Shot Alignment of Large Language Models](https://arxiv.org/abs/2310.11523)
- (5-2023) [Training Socially Aligned Language Models on Simulated Social Interactions](https://arxiv.org/abs/2305.16960)
- (4-2023) [In Conversation with Artificial Intelligence: Aligning Language Models with Human Values](https://link.springer.com/article/10.1007/s13347-023-00606-x)
- (2020) [Artificial Intelligence, Values, and Alignment](https://link.springer.com/article/10.1007/s11023-020-09539-2)


## How to Contribute
We welcome contributions! You can help by:
- **Adding New Resources**: Share new findings or resources.
- **Updating Existing Entries**: Ensure information is up-to-date and accurate.
- **Enhancing Organization**: Offer suggestions for a more user-friendly experience or a better structure.

To contribute:
1. Fork the repository.
2. Make your changes.
3. Submit a pull request with a detailed description of your changes.

### Contact
Have questions or suggestions? Feel free to [contact us](mailto:iftitahu@gmail.com).
